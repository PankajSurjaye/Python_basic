{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aec173-0bae-4d2d-b913-603841486831",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the role of feature selection in anomaly detection?\n",
    "\n",
    "Feature selection plays a crucial role in anomaly detection by identifying the most relevant features that capture the underlying structure of normal and anomalous instances.\n",
    "It helps in reducing the dimensionality of the data, improving computational efficiency, and enhancing the performance of anomaly detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394fb170-dfbe-42f6-8223-42be33e24076",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are some common evaluation metrics for anomaly detection algorithms and how are they computed?\n",
    "\n",
    "Common evaluation metrics for anomaly detection include:\n",
    "Precision, Recall, F1-score: Computed based on the true positives, false positives, and false negatives.\n",
    "Area Under the ROC Curve (AUC-ROC): Measures the ability of the model to discriminate between normal and anomalous instances.\n",
    "Area Under the Precision-Recall Curve (AUC-PR): Evaluates the precision-recall trade-off of the model.\n",
    "Mean Squared Error (MSE): Measures the average squared difference between predicted and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92000eee-39d7-47a1-b65c-efc15eadd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision - 0.6666666666666666\n",
      "recall - 0.6666666666666666\n",
      "f1 - 0.6666666666666666\n",
      "auc_roc - 0.5833333333333333\n",
      "mse - 0.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Dummy true labels and predictions\n",
    "y_true = np.array([0, 1, 1, 0, 1])\n",
    "y_pred = np.array([0, 1, 0, 1, 1])\n",
    "\n",
    "# Example usage\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "auc_roc = roc_auc_score(y_true, y_pred)  # Note: y_score is not required here\n",
    "auc_pr = average_precision_score(y_true, y_pred)  # Note: y_score is not required here\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print('precision','-',precision)\n",
    "print('recall','-',recall)\n",
    "print('f1','-',f1)\n",
    "print('auc_roc','-',auc_roc)\n",
    "print('mse','-',mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1b335-01df-45a8-a658-56caa3f338ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is DBSCAN and how does it work for clustering?\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm that groups together closely packed points based on a density threshold.\n",
    "It forms clusters by identifying regions of high density separated by regions of low density, and it can discover clusters of arbitrary shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3709bab-de59-4ae0-a906-3178f4aac8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. How does the epsilon parameter affect the performance of DBSCAN in detecting anomalies?\n",
    "\n",
    "The epsilon parameter in DBSCAN determines the radius within which points are considered neighbors. Smaller values of epsilon will result in tighter clusters and potentially more anomalies, \n",
    "while larger values may merge clusters and reduce the number of anomalies detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab00bdb-58c2-4ba8-8ea0-b49f26529655",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. What are the differences between the core, border, and noise points in DBSCAN, and how do they relate to anomaly detection?\n",
    "\n",
    "Core points: Points that have at least min_samples number of points (including itself) within a distance of epsilon. These points are at the interior of a cluster.\n",
    "Border points: Points that are within the epsilon distance of a core point but do not satisfy the min_samples condition. They are on the edge of a cluster.\n",
    "Noise points: Points that are neither core nor border points. They are considered outliers or anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40685cd-110a-4cfe-bb73-6f50666e3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. How does DBSCAN detect anomalies and what are the key parameters involved in the process?\n",
    "\n",
    "DBSCAN can detect anomalies as noise points, i.e., points that do not belong to any cluster.\n",
    "The key parameters involved are epsilon (the maximum distance between two samples for one to be considered as in the neighborhood of the other) and min_samples (the number of samples in a neighborhood for a point to be considered a core point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f4b0a-eeba-47d2-b345-7b9d46992c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. What is the make_circles package in scikit-learn used for?\n",
    "\n",
    "The make_circles function in scikit-learn is used to generate synthetic data with concentric circles. It is often used for testing clustering algorithms, including DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05df0de9-bd75-462f-874e-db7e02899469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Generate data with two circles\n",
    "X, _ = make_circles(n_samples=1000, noise=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ee569-b19c-4c4d-9555-b36640bb1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. What are local outliers and global outliers, and how do they differ from each other?\n",
    "\n",
    "Local outliers: Points that are anomalies within their local neighborhood but may appear normal in the global context. They have low local density compared to their neighbors.\n",
    "Global outliers: Points that are anomalies when considering the entire dataset. They have low density compared to all points in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12b7ab9-c171-42ca-81bc-bf84cfdb8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. How can local outliers be detected using the Local Outlier Factor (LOF) algorithm?\n",
    "\n",
    "The LOF algorithm computes a score for each data point based on its local density compared to the local densities of its neighbors.\n",
    "Points with significantly lower density compared to their neighbors are considered local outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061fcf2-47e3-4601-b004-fbe80ca183c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. How can global outliers be detected using the Isolation Forest algorithm?\n",
    "\n",
    "The Isolation Forest algorithm identifies global outliers by isolating them in the feature space through random partitioning.\n",
    "It measures the number of splits required to isolate a data point, and points that require fewer splits are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ae4d5-afbc-4f6b-9067-d018b41bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. What are some real-world applications where local outlier detection is more appropriate than global outlier detection, and vice versa?\n",
    "\n",
    "Local outlier detection is more appropriate in applications where anomalies occur in clusters or localized regions, such as network intrusion detection or fraud detection in localized areas.\n",
    "Global outlier detection is suitable for applications where anomalies are spread across the entire dataset, such as manufacturing quality control or anomaly detection in financial transactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
